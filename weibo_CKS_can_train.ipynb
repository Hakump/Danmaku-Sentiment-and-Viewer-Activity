{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from transformers import *\n",
    "import torch.utils.data as Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 854/854 [00:00<00:00, 227kB/s]\n",
      "Downloading: 100%|██████████| 390M/390M [00:20<00:00, 19.5MB/s]\n",
      "Downloading: 100%|██████████| 377/377 [00:00<00:00, 173kB/s]\n",
      "Downloading: 100%|██████████| 107k/107k [00:00<00:00, 2.13MB/s]\n",
      "Downloading: 100%|██████████| 263k/263k [00:00<00:00, 2.50MB/s]\n",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 115kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead, AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "\n",
    "# model_name = \"hfl/chinese-xlnet-base\"\n",
    "model_name = \"liam168/c2-roberta-base-finetuned-dianping-chinese\"\n",
    "# class_num = 4 # weibo-text.csv, 0:happy, 1:angry, 2:disgust, 3:down/upset\n",
    "class_num = 2 # positive or negative\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=class_num)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "max_len = 200\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'啊呀呀 要死 穿 外套 认为 里面 件 余 周小伦 喜歡 各種 五角星 項鏈 露胸 衣服 伦伦 真的 越来越 帅'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./weibo-text.csv', encoding='utf-8')\n",
    "df['text'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_texts = [\"我喜欢下雨。\", \"我讨厌他.\"]\n",
    "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.9902541041374207}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(ts_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative', 'score': 0.9941973686218262}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(ts_texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.9864313006401062}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(df['text'].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['啊呀呀 要死 穿 外套 认为 里面 件 余 周小伦 喜歡 各種 五角星 項鏈 露胸 衣服 伦伦 真的 越来越 帅',\n",
       "       '风格 喜欢 喜欢 张',\n",
       "       '试试 去死皮 面膜 燕麦片 加水 中 浸泡 小时 加入 木瓜 牛奶 搅拌 放入 压缩 纸 面膜 敷于 脸上 分钟 清水 洗净 改善 粗糙 肌肤 去除 死皮 肌肤 光滑',\n",
       "       '张老师 谢谢 侬 信任 粉丝 无所谓 重 质地 近日 发现 现象 加 关注 回加 立即 取消 关注 回应 立即 取消 关注'],\n",
       "      dtype='<U83')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].loc[:3].values.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len = 100\n",
    "model_output = []\n",
    "for i in range(test_len):\n",
    "  model_output.append(classifier(df['text'].loc[i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(\"chnsenticorp/dev.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>這間酒店環境和服務態度亦算不錯,但房間空間太小~~不宣容納太大件行李~~且房間格調還可以~~...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;荐书&gt; 推荐所有喜欢&lt;红楼&gt;的红迷们一定要收藏这本书,要知道当年我听说这本书的时候花很长时...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>商品的不足暂时还没发现，京东的订单处理速度实在.......周二就打包完成，周五才发货...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>２００１年来福州就住在这里，这次感觉房间就了点，温泉水还是有的．总的来说很满意．早餐简单了些．</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>不错的上网本，外形很漂亮，操作系统应该是个很大的 卖点，电池还可以。整体上讲，作为一个上网本...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             text_a\n",
       "0      1  這間酒店環境和服務態度亦算不錯,但房間空間太小~~不宣容納太大件行李~~且房間格調還可以~~...\n",
       "1      1  <荐书> 推荐所有喜欢<红楼>的红迷们一定要收藏这本书,要知道当年我听说这本书的时候花很长时...\n",
       "2      0     商品的不足暂时还没发现，京东的订单处理速度实在.......周二就打包完成，周五才发货...\n",
       "3      1    ２００１年来福州就住在这里，这次感觉房间就了点，温泉水还是有的．总的来说很满意．早餐简单了些．\n",
       "4      1  不错的上网本，外形很漂亮，操作系统应该是个很大的 卖点，电池还可以。整体上讲，作为一个上网本..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len = 200\n",
    "model_output = []\n",
    "for i in range(test_len):\n",
    "  one_output = classifier(new_df['text_a'].loc[i])[0]\n",
    "  one_output = 1 if one_output['label'] == 'positive' else 0\n",
    "  model_output.append(one_output)\n",
    "model_output = np.array(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels = new_df['label'].loc[:199].values\n",
    "true_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(model_output==true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 1557, 1435, 1435, 6206, 3647, 4959, 1912, 1947, 6371,  711, 7027,\n",
       "         7481,  816,  865, 1453, 2207,  840, 1599, 3631, 1392, 4934,  758, 6235,\n",
       "         3215, 7517, 7122, 7463, 5541, 6132, 3302,  840,  840, 4696, 4638, 6632,\n",
       "         3341, 6632, 2358,  102]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings = tokenizer(df['text'].loc[0], return_tensors='pt', padding=True)\n",
    "train_encodings['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.0137, grad_fn=<NllLossBackward0>), logits=tensor([[-2.1138,  2.1725]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict = tokenizer.encode_plus(\n",
    "            df['text'].loc[0],\n",
    "            add_special_tokens = True,\n",
    "            max_length = 200,\n",
    "            padding='longest',\n",
    "            return_tensors = 'pt',\n",
    "        )\n",
    "model(encoded_dict['input_ids'], token_type_ids=encoded_dict['token_type_ids'], attention_mask=encoded_dict['attention_mask'], labels=torch.tensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def process_data(filename):\n",
    "#   with open(filename, 'r') as f:\n",
    "#     rows = [row for row in csv.reader(f)]\n",
    "#     rows = np.array(rows[1:])\n",
    "#     comments = []\n",
    "#     labels = []\n",
    "#     for c, l in rows:\n",
    "#       comments.append(c)\n",
    "#       labels.append(l)\n",
    "#     classes = list(set(labels))\n",
    "#     num_classes = len(classes)\n",
    "#     # print(comments, labels)\n",
    "#     return  comments,  labels, classes,   num_classes\n",
    "def process_data(filename=\"text.csv\"):\n",
    "    f = pd.read_csv(filename)\n",
    "    comment = f['text'].to_numpy()\n",
    "    label = f['label'].to_numpy()\n",
    "    return comment, label, set(label)\n",
    "\n",
    "# a, b, c = process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def encode(comments, labels, max_len):\n",
    "    input_id_list, token_type_ids, attention_mask = [], [], []\n",
    "    print(\"len78\")\n",
    "    print(len(comments))\n",
    "    # print(type(input_id_list))\n",
    "    for i in range(len(comments)):\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                comments[i],\n",
    "                add_special_tokens = True,\n",
    "                max_length = max_len,\n",
    "                pad_to_max_length = True,\n",
    "                return_tensors = 'pt',\n",
    "            )\n",
    "\n",
    "        # print(type(input_id_list))\n",
    "        input_id_list.append(encoded_dict['input_ids'])\n",
    "        token_type_ids.append(encoded_dict['token_type_ids'])\n",
    "        attention_mask.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # onehot_encoder = OneHotEncoder()\n",
    "    # labels = onehot_encoder.fit_transform(np.array(labels).reshape(-1, 1)).toarray()\n",
    "\n",
    "    input_id_list = torch.cat(input_id_list, dim=0)\n",
    "    token_type_ids = torch.cat(token_type_ids, dim=0)\n",
    "    attention_mask = torch.cat(attention_mask, dim=0)\n",
    "\n",
    "    input_id_list = torch.LongTensor(input_id_list)\n",
    "    token_type_ids = torch.LongTensor(token_type_ids)\n",
    "    attention_mask = torch.LongTensor(attention_mask)\n",
    "    labels = torch.LongTensor(labels)\n",
    "    print(\"len103\")\n",
    "    print(len(input_id_list))\n",
    "    return input_id_list, token_type_ids, attention_mask, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional\n",
    "\n",
    "output_dir = './models/'\n",
    "output_model_file = os.path.join(output_dir, 'parameters')\n",
    "output_config_file = os.path.join(output_dir, 'config')\n",
    "\n",
    "def save(model):\n",
    "    # save\n",
    "    torch.save(model.state_dict(), output_model_file)\n",
    "    model.config.to_json_file(output_config_file)\n",
    "\n",
    "def eval(model, dataloader):\n",
    "    model.eval()\n",
    "    loss, num_examples, accuracy, correct_pred = 0, 0, 0, 0\n",
    "    for batch in dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        with torch.no_grad():\n",
    "            logits = model(batch[0], token_type_ids=batch[1], attention_mask=batch[2])[0]\n",
    "            probas = torch.nn.functional.softmax(logits, dim = 1)\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label = batch[3]\n",
    "            probas = torch.nn.functional.softmax(logits, label)\n",
    "\n",
    "            loss += torch.nn.functional.cross_entropy(logits, label).item()\n",
    "\n",
    "            _, predicted_labels = torch.max(probas, 1)\n",
    "            num_examples += label.size(0)\n",
    "            correct_pred += (predicted_labels == label).sum()\n",
    "            # eval_accuracy += tmp_eval_accuracy\n",
    "            # nb_eval_steps += 1\n",
    "    return correct_pred.item()/num_examples * 100, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'softmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/91/k7kc8dhd3fx3jqyt9x_v0yw00000gn/T/ipykernel_3647/3685577932.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/91/k7kc8dhd3fx3jqyt9x_v0yw00000gn/T/ipykernel_3647/2354483958.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/exercism/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1678\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1680\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1681\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'softmax'"
     ]
    }
   ],
   "source": [
    "eval(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len78\n",
      "265433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kesong/miniconda3/envs/exercism/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len103\n",
      "265433\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AdamW\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "comments,  labels, classes = process_data()\n",
    "num_classes = len(classes)\n",
    "\n",
    "# input_ids, token_type_ids, attention_mask, labels = encode(comments,  labels, max_len)\n",
    "input_ids, token_type_ids, attention_mask, labels = encode(comments,  labels, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, input_test, label_train, label_test_ = train_test_split(input_ids, labels, test_size=0.4, random_state=42)\n",
    "input_val, input_test, label_val, label_test = train_test_split(input_test, label_test_, test_size=0.5, random_state=42)\n",
    "\n",
    "token_train, token_test, _, _ = train_test_split(token_type_ids, labels, test_size=0.4, random_state=42)\n",
    "token_val, token_test,  _, _ = train_test_split(token_test, label_test_, test_size=0.5, random_state=42)\n",
    "\n",
    "mask_train, mask_test, _, _ = train_test_split(attention_mask, labels, test_size=0.4, random_state=42)\n",
    "mask_val, mask_test,  _, _ = train_test_split(mask_test, label_test_, test_size=0.5, random_state=42)\n",
    "\n",
    "train_data = Data.TensorDataset(input_train, token_train, mask_train, label_train)\n",
    "train_dataloader = Data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_data = Data.TensorDataset(input_val, token_val, mask_val, label_val)\n",
    "val_dataloader = Data.DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = Data.TensorDataset(input_test, token_test, mask_test, label_test)\n",
    "test_dataloader = Data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_dataloader):\n",
    "  print(\"i=\", i)\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(batch[0], token_type_ids=batch[1], attention_mask=batch[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1730,  0.0845,  0.0520,  0.3221],\n",
       "        [-0.1082,  0.2527, -0.1241,  0.3594]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(batch[0], token_type_ids=batch[1], attention_mask=batch[2], labels=batch[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n",
      "1.3852424621582031\n",
      "i= 1\n",
      "1.3356711864471436\n",
      "i= 2\n",
      "1.186072826385498\n",
      "i= 3\n",
      "1.2101402282714844\n",
      "i= 4\n",
      "1.5175080299377441\n",
      "i= 5\n",
      "1.3342182636260986\n",
      "i= 6\n",
      "1.0642211437225342\n",
      "i= 7\n",
      "1.2318025827407837\n",
      "i= 8\n",
      "1.0291621685028076\n",
      "i= 9\n",
      "0.8866887092590332\n",
      "i= 10\n",
      "0.7873426079750061\n",
      "i= 11\n",
      "0.7226966619491577\n",
      "i= 12\n",
      "0.601564347743988\n",
      "i= 13\n",
      "1.8192312717437744\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(model_name, epochs):\n",
    "  param_optimizer = list(model.named_parameters())\n",
    "  no_decay = ['bias', 'gamma', 'beta']\n",
    "  optimizer_grouped_parameters = [\n",
    "      {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "      'weight_decay_rate': 0.01},\n",
    "      {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "      'weight_decay_rate': 0.0}]\n",
    "\n",
    "  optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
    "\n",
    "  for _ in range(epochs):\n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            print(\"i=\", i)\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            loss = model(batch[0], token_type_ids=batch[1], attention_mask=batch[2], labels=batch[3])[0]\n",
    "            # predictions = F.softmax(logits, dim=-1)\n",
    "\n",
    "            print(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # if i % 10 == 0:\n",
    "            #   train_acc, train_loss = eval(model, train_dataloader)\n",
    "            #   val_acc, val_loss = eval(model, val_dataloader)\n",
    "\n",
    "            #   print(f'Train Accuracy: {train_acc:.2f}% Loss: {train_loss:.4f}, Val Accuracy: {val_acc:.2f}% ')\n",
    "\n",
    "train(model_name, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-9d6bf8ba80f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# print(input_ids.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# print(labels.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# print(len(input_test))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# print(len(label_train))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# len(comments)\n",
    "# len(labels)\n",
    "# input_train, input_test, label_train, label_test = train_test_split(input_ids, labels, test_size=0.4, random_state=42)\n",
    "# input_ids, token_type_ids, attention_mask, labels = encode(comments,  labels, max_len)\n",
    "# print(input_ids.shape)\n",
    "# print(labels.shape)\n",
    "print(train_data.shape)\n",
    "# print(len(input_test))\n",
    "# print(len(label_train))\n",
    "# print(len(label_test ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
